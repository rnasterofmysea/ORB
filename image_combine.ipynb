{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiCuKxH7EjqT"
      },
      "outputs": [],
      "source": [
        "import cv2, numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def concat(img1, img2)\n",
        "  gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "  gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # ORB, BF-Hamming 로 knnMatch  ---①\n",
        "  detector = cv2.ORB_create()\n",
        "  kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
        "  kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
        "  matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "  matches = matcher.match(desc1, desc2)\n",
        "\n",
        "  # 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
        "  matches = sorted(matches, key=lambda x:x.distance)\n",
        "  # for match in matches:\n",
        "  #     print(f\"img1:{kp1[match.queryIdx].pt} - img2:{kp2[match.queryIdx].pt}\")\n",
        "    \n",
        "  # 모든 매칭점 그리기 ---④\n",
        "  res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
        "                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "  # 매칭점으로 원근 변환 및 영역 표시 ---⑤\n",
        "  src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ])\n",
        "  dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ])\n",
        "\n",
        "  # RANSAC으로 변환 행렬 근사 계산 ---⑥\n",
        "  mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "  h,w = img1.shape[:2]\n",
        "  pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
        "  dst = cv2.perspectiveTransform(pts,mtrx)\n",
        "  #img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
        "\n",
        "  # 정상치 매칭만 그리기 ---⑦\n",
        "  matchesMask = mask.ravel().tolist()\n",
        "  res2 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
        "                      matchesMask = matchesMask,\n",
        "                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "  # 모든 매칭점과 정상치 비율 ---⑧\n",
        "  accuracy=float(mask.sum()) / mask.size\n",
        "  print(\"accuracy: %d/%d(%.2f%%)\"% (mask.sum(), mask.size, accuracy))\n",
        "\n",
        "  # warped_image = cv2.warpPerspective(img1, mtrx, (img2.shape[1], img2.shape[0]))\n",
        "  # cv2.imwrite(\"test.jpg\", warped_image)\n",
        "\n",
        "  #정상치 매칭 키포인트 리스트\n",
        "  kp1_list = []\n",
        "  kp2_list = []\n",
        "  i = 0\n",
        "\n",
        "  # 정상치 매칭 키포인트 저장\n",
        "  while i < len(matchesMask):\n",
        "      if matchesMask[i] == 1:\n",
        "          print(f\"img1:{kp1[matches[i].queryIdx].pt} - img2:{kp2[matches[i].queryIdx].pt}\")\n",
        "          kp1_list.append(kp1[matches[i].queryIdx])\n",
        "          kp2_list.append(kp2[matches[i].queryIdx])\n",
        "      i = i + 1\n",
        "\n",
        "  # vector -> point 자료형 변경\n",
        "\n",
        "  kp1_tuple_list = []\n",
        "  kp2_tuple_list = []\n",
        "\n",
        "  for k in kp1_list:\n",
        "    kp1_tuple_list.append(k.pt)\n",
        "    \n",
        "  for k in kp2_list:\n",
        "    kp2_tuple_list.append(k.pt)\n",
        "\n",
        "  # padas dataFrame 변환\n",
        "  df1 = pd.DataFrame(kp1_tuple_list, columns=['x','y'])\n",
        "  df2 = pd.DataFrame(kp2_tuple_list, columns=['x','y'])\n",
        "\n",
        "  # x 최대값 추출\n",
        "  roi_point1=df1['x'].max()\n",
        "  roi_point2=df2['x'].max()\n",
        "\n",
        "  # 이미지 roi\n",
        "  h1,w1,c1 = img1.shape\n",
        "  h2,w2,c2 = img2.shape\n",
        "  roi1 = img1[0:h1,0:int(roi_point1)]\n",
        "  roi2 = img2[0:h2,int(roi_point2):w2]\n",
        "\n",
        "  # 이미지 concat\n",
        "  result = np.concatenate([roi1,roi2], axis = 0)\n",
        "  return result \n",
        "  # 결과 출력                    \n",
        "  \n",
        "  #from google.colab.patches import cv2_imshow      \n",
        "\n",
        "  #cv2_imshow(result)\n",
        "  #cv2.waitKey()\n",
        "  #cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "dir =\"./\"\n",
        "img_list = []\n",
        "combine_image = None\n",
        "\n",
        "# 디렉토리 내부 사진 읽어오기\n",
        "for f in os.listdir(dir):\n",
        "  path = dir + f\n",
        "  img_list.append(cv2.imread(path))\n",
        "\n",
        "i = 0\n",
        "while i < len(img_list) - 1:\n",
        "  combine_img = combine(k[i],k[i+1])\n",
        "  i +=1\n",
        "\n",
        "cv2.imwrite(\"combine.jpg\",combine)"
      ],
      "metadata": {
        "id": "UuG7nJgrGHN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}